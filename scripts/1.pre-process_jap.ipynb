{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8eacb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# September 2025\n",
    "# Script to preprocess data from wos and ce database\n",
    "# Violeta Berdejo-Espinola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd7e9b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install polars _FastText numpy fastexcel\n",
    "\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4cf3a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to normalize text\n",
    "\n",
    "import unicodedata\n",
    "\n",
    "def normalize_text(text):\n",
    "    text = text.strip().replace(\"\\n\", \"\")\n",
    "    text = text.replace(\"\\n\", \"\")\n",
    "    return unicodedata.normalize('NFKC', text)\n",
    "# @params: (form unistr) --> convert strings to one of the four Unicode normalization forms NFC, NFD, NFKC, NFKD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75749fbe",
   "metadata": {},
   "source": [
    "# read repo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f53fbd30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "articles in repo raw: 7713\n"
     ]
    }
   ],
   "source": [
    "# read repo data\n",
    "\n",
    "df_repo = pl.read_csv('../data/from_majom/majom_japanese_040725.csv')\n",
    "print(f'articles in repo raw: {len(df_repo)}')\n",
    "\n",
    "# rename columns journal name\n",
    "\n",
    "df_repo = df_repo.rename({\"name\": \"journal\",\n",
    "                \"pub_year\": \"year\"\n",
    "                })\n",
    "\n",
    "# normalize journal name, article title, and abastract\n",
    "\n",
    "df_repo = df_repo.with_columns(\n",
    "    pl.col('title_en')\n",
    "    .map_elements(normalize_text, return_dtype=pl.Utf8).alias(\"title_en\"),\n",
    "    pl.col('title_ja')\n",
    "    .map_elements(normalize_text, return_dtype=pl.Utf8).alias(\"title_ja\"),\n",
    "    pl.col('abstract_en')\n",
    "    .map_elements(normalize_text, return_dtype=pl.Utf8).alias('abstract_en'),\n",
    "    pl.col('abstract_ja')\n",
    "    .map_elements(normalize_text, return_dtype=pl.Utf8).alias('abstract_ja'),\n",
    "    pl.col(\"journal\")\n",
    "    .map_elements(normalize_text, return_dtype=pl.Utf8).alias(\"journal\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256bc490",
   "metadata": {},
   "source": [
    "# detect language of titles in repo \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcbcc5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "articles in repo: 7713\n",
      "articles in repo japanese only: 5321\n",
      "non-japanese articles removed from repo: 219\n",
      "non-japanese articles removed from repo: 2246\n"
     ]
    }
   ],
   "source": [
    "from fasttext.FastText import _FastText\n",
    "\n",
    "model_path = 'lid.176.ftz'\n",
    "model = _FastText(model_path=model_path)\n",
    "\n",
    "# function to detect languages\n",
    "\n",
    "def get_lang(text: str) -> str:\n",
    "    lang, _ = model.predict(text)\n",
    "    lang = lang[0].removeprefix('__label__')\n",
    "    # conf = conf[0]\n",
    "\n",
    "    return lang\n",
    "\n",
    "# detect languages\n",
    "\n",
    "df_repo = df_repo.with_columns(\n",
    "    pl.col(\"title_ja\")\n",
    "    .map_elements(get_lang, return_dtype=pl.Utf8).alias(\"language\"),\n",
    "    pl.col(\"abstract_ja\")\n",
    "    .map_elements(get_lang, return_dtype=pl.Utf8).alias(\"language_abs\")\n",
    ")\n",
    "print(f'articles in repo: {len(df_repo)}')\n",
    "\n",
    "languages = df_repo[\"language\"].value_counts()\n",
    "\n",
    "# filter japanese only\n",
    "\n",
    "df_other_lang_title = df_repo.filter(\n",
    "    pl.col('language') != 'ja')\n",
    "\n",
    "df_other_lang_abstract = df_repo.filter(\n",
    "    pl.col('language_abs') != 'ja')\n",
    "\n",
    "df_repo = df_repo.filter(\n",
    "    pl.col('language') == 'ja')\n",
    "\n",
    "df_repo = df_repo.filter(\n",
    "    pl.col('language_abs') == 'ja')\n",
    "\n",
    "print(f'articles in repo japanese only: {len(df_repo)}')\n",
    "print(f'non-japanese articles removed from repo: {len(df_other_lang_title)}')\n",
    "print(f'non-japanese articles removed from repo: {len(df_other_lang_abstract)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68469b2",
   "metadata": {},
   "source": [
    "# remove unwanted articles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "427f69cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "articles in repo: 5305 -> editorials, in memoriam removed\n",
      "articles in repo with english titles dupes: 37\n",
      "articles in repo with japanese titles dupes: 40\n",
      "articles in repo no dupes: 5278\n"
     ]
    }
   ],
   "source": [
    "df_repo = df_repo.filter(\n",
    "    ~pl.col(\"title_en\").str.contains(\"In Memoriam|Editorial|Correction|Notes|Untitled|Retracted\"))\n",
    "\n",
    "print(f'articles in repo: {len(df_repo)} -> editorials, in memoriam removed')\n",
    "\n",
    "# drop duplicates and nas\n",
    "\n",
    "df_repo_dupes_en = df_repo.filter(\n",
    "    pl.col(\"title_en\").is_duplicated())\n",
    "df_repo_dupes_ja = df_repo.filter(\n",
    "    pl.col(\"title_ja\").is_duplicated())\n",
    "\n",
    "df_repo = df_repo.unique(subset=['title_ja'])\n",
    "df_repo = df_repo.unique(subset=['title_en'])\n",
    "\n",
    "# print(f'NAs in repo:\\n{df_repo.isna().sum()}')\n",
    "print(f'articles in repo with english titles dupes: {len(df_repo_dupes_en)}')\n",
    "print(f'articles in repo with japanese titles dupes: {len(df_repo_dupes_ja)}')\n",
    "print(f'articles in repo no dupes: {len(df_repo)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc859a6e",
   "metadata": {},
   "source": [
    "# read pos data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60e5c901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "articles in positives raw: 326\n",
      "articles in positive dupes: 11\n",
      "articles in positives no dupes: 316\n",
      "articles with no abstract: 130\n"
     ]
    }
   ],
   "source": [
    "# translate data \n",
    "\n",
    "df_pos = pl.read_excel('../data/from_translate/Master_Japanese copy.xlsx')\n",
    "print(f'articles in positives raw: {len(df_pos)}')\n",
    "\n",
    "# rename columns\n",
    "\n",
    "df_pos = df_pos.rename({\n",
    "    'Title - non-English language':'title_ja',\n",
    "    'Title - English': 'title_en',\n",
    "    'Abstract - non-English': 'abstract_ja',\n",
    "    'Journal':'journal',\n",
    "    'Language': 'language',\n",
    "    'Year': 'year'\n",
    "})\n",
    "\n",
    "# normalize journal name, article title, abstract\n",
    " \n",
    "df_pos = df_pos.with_columns(\n",
    "    pl.col('title_ja')\n",
    "    .map_elements(normalize_text, return_dtype=pl.Utf8),\n",
    "    pl.col('title_en')\n",
    "    .map_elements(normalize_text, return_dtype=pl.Utf8),\n",
    "    pl.col('abstract_ja')\n",
    "    .map_elements(normalize_text, return_dtype=pl.Utf8),\n",
    "    pl.col('journal')\n",
    "    .map_elements(normalize_text, return_dtype=pl.Utf8)\n",
    ")\n",
    "\n",
    "# subset metadata\n",
    "\n",
    "df_pos = df_pos.select(\n",
    "    pl.col(['title_ja', 'title_en', 'abstract_ja', 'journal', 'year']\n",
    "           )\n",
    ")\n",
    "\n",
    "# drop duplicates and nas/empty strings\n",
    "\n",
    "df_pos_dupes = df_pos.filter(\n",
    "    pl.col(\"title_en\").is_duplicated()\n",
    ")\n",
    "\n",
    "df_pos = df_pos.unique(subset=['title_ja'])\n",
    "df_pos = df_pos.unique(subset=['title_en'])\n",
    "\n",
    "df_empty_strings = df_pos.filter(\n",
    "    pl.col(\"abstract_ja\") == \"\")\n",
    "\n",
    "# df_pos = df_pos.filter(\n",
    "#     pl.col(\"abstract_ja\") != \"\")\n",
    "\n",
    "print(f\"articles in positive dupes: {len(df_pos_dupes)}\")\n",
    "print(f'articles in positives no dupes: {len(df_pos)}')\n",
    "print(f\"articles with no abstract: {len(df_empty_strings)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2079f077",
   "metadata": {},
   "source": [
    "# detect language of titles in pos and repo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "355d42c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "japanese pos articles: 307\n",
      "non-japanese articles removed from pos: 9\n"
     ]
    }
   ],
   "source": [
    "# remove or replace newlines with spaces -> lang detector returns error otherwise\n",
    "\n",
    "df_pos = df_pos.with_columns(\n",
    "    pl.col('title_ja')\n",
    "    .str.replace_all(r\"\\n\", \" \")  \n",
    ")\n",
    "\n",
    "# detect languages\n",
    "\n",
    "df_pos = df_pos.with_columns(\n",
    "    pl.col('title_ja')\n",
    "    .map_elements(get_lang, return_dtype=pl.Utf8)\n",
    "    .alias('language')\n",
    ")\n",
    "\n",
    "# filter japanese only\n",
    "\n",
    "df_pos_other_lang = df_pos.filter(\n",
    "    pl.col('language') != 'ja')\n",
    "\n",
    "df_pos = df_pos.filter(\n",
    "    pl.col('language') == 'ja')\n",
    "\n",
    "df_pos = df_pos.filter(\n",
    "    pl.col('language') == 'ja')\n",
    "\n",
    "print(f'japanese pos articles: {len(df_pos)}')\n",
    "print(f'non-japanese articles removed from pos: {len(df_pos_other_lang)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a47224a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pos[\"abstract_ja\"].null_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a578960",
   "metadata": {},
   "source": [
    "# restrict year range\n",
    "documents in repo outside year range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f53874b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "journals in pos: 19\n"
     ]
    }
   ],
   "source": [
    "df_pos_journal = df_pos[\"journal\"].unique()\n",
    "print(f\"journals in pos: {len(df_pos_journal)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a02d61d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5278 108 307\n"
     ]
    }
   ],
   "source": [
    "# journal years in repo \n",
    "\n",
    "df_repo_journals = df_repo.group_by(\n",
    "    pl.col(\"journal\")).agg(by=pl.col(\"year\")\n",
    "                           .unique()\n",
    "                           .sort()\n",
    "                           .cast(pl.Int64)\n",
    "                           )\n",
    "    \n",
    "df_repo_journals = df_repo_journals.explode(\"by\")\n",
    "\n",
    "# apply the filter dynamically\n",
    "\n",
    "df_pos_filtered = df_pos.join(df_repo_journals , left_on=[\"year\",\"journal\"], right_on=[\"by\", \"journal\"], how='semi')\n",
    "\n",
    "df_repo_filtered = df_repo.join(df_repo_journals , left_on=[\"year\",\"journal\"], right_on=[\"by\", \"journal\"], how='semi')\n",
    "\n",
    "print(len(df_repo_filtered), len(df_pos_filtered), len(df_pos))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e2e6c3",
   "metadata": {},
   "source": [
    "# titles in pos that are in repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd1774b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>exists_in_repo</th><th>count</th></tr><tr><td>bool</td><td>u32</td></tr></thead><tbody><tr><td>true</td><td>76</td></tr><tr><td>false</td><td>231</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2, 2)\n",
       "┌────────────────┬───────┐\n",
       "│ exists_in_repo ┆ count │\n",
       "│ ---            ┆ ---   │\n",
       "│ bool           ┆ u32   │\n",
       "╞════════════════╪═══════╡\n",
       "│ true           ┆ 76    │\n",
       "│ false          ┆ 231   │\n",
       "└────────────────┴───────┘"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pos = df_pos.with_columns(\n",
    "    pl.col('title_en')\n",
    "    .is_in(df_repo_filtered['title_en'])\n",
    "    .alias(\"exists_in_repo\")\n",
    "    )\n",
    "\n",
    "df_pos[\"exists_in_repo\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f808226d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to disk \n",
    "df_pos.write_csv('../data/outputs_pre-processing/pos_jap_pre-processed.csv')\n",
    "df_pos_dupes.write_csv('../data/outputs_pre-processing/pos_jap_duplicates_removed.csv')\n",
    "df_pos_other_lang.write_csv('../data/outputs_pre-processing/pos_jap_nonjap_removed.csv')\n",
    "df_empty_strings.write_csv('../data/outputs_pre-processing/pos_jap_empty_abstract.csv')\n",
    "\n",
    "df_repo.write_csv('../data/outputs_pre-processing/repo_jap_pre-processed.csv')\n",
    "df_repo_filtered.write_csv('../data/outputs_pre-processing/repo_jap_pre-processed_year_range_ok.csv') \n",
    "df_repo_dupes_en.write_csv('../data/outputs_pre-processing/repo_jap_en_duplicates_removed.csv')\n",
    "df_repo_dupes_ja.write_csv('../data/outputs_pre-processing/repo_jap_ja_duplicates_removed.csv') \n",
    "df_other_lang_abstract.write_csv(\"../data/outputs_pre-processing/repo_jap_nonjap_abs_removed.csv\")\n",
    "df_other_lang_title.write_csv(\"../data/outputs_pre-processing/repo_jap_nonjap_title_removed.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
